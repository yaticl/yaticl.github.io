
<!DOCTYPE html>
<html lang="zh_tw">
<head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="robots" content="" />

  <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro|Source+Sans+Pro:300,400,400i,700" rel="stylesheet">

    <link rel="stylesheet" type="text/css" href="https://yaticl.github.io/theme/stylesheet/style.min.css">


    <link id="pygments-light-theme" rel="stylesheet" type="text/css"
          href="https://yaticl.github.io/theme/pygments/github.min.css">

    <script src="https://yaticl.github.io/theme/tipuesearch/jquery.min.js"></script>
    <script src="https://yaticl.github.io/theme/tipuesearch/tipuesearch.min.js"></script>
    <script src="https://yaticl.github.io/theme/tipuesearch/tipuesearch.min.js"></script>
    <script src="https://yaticl.github.io/theme/tipuesearch/tipuesearch_set.min.js"></script>
    <script src="https://yaticl.github.io/tipuesearch_content.js"></script>
    <link rel="stylesheet" href="https://yaticl.github.io/theme/tipuesearch/tipuesearch.min.css" />

  <link rel="stylesheet" type="text/css" href="https://yaticl.github.io/theme/font-awesome/css/fontawesome.css">
  <link rel="stylesheet" type="text/css" href="https://yaticl.github.io/theme/font-awesome/css/brands.css">
  <link rel="stylesheet" type="text/css" href="https://yaticl.github.io/theme/font-awesome/css/solid.css">


    <link href="https://yaticl.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Ya-Ti's Blog Atom">


    <link rel="shortcut icon" href="https://yaticl.github.io/icons/favicon.ico" type="image/x-icon">
    <link rel="icon" href="https://yaticl.github.io/icons/favicon.ico" type="image/x-icon">



<meta name="author" content="Ya-Ti" />
<meta name="description" content="2024-05-24 更新：由於 ONNX QNN EP 文件更新很多，因此文章因應而大幅更新。 背景 由於最近生成式 AI 的興起，如 ChatGPT 與 DALL·E，微軟攜手廠商們 …" />
<meta name="keywords" content="Machine Learning, AI, ONNX, DirectML, ARM64">


<meta property="og:site_name" content="Ya-Ti's Blog"/>
<meta property="og:title" content="使用 ONNX Runtime 與 Qualcomm QNN 加速影像分類模型推理"/>
<meta property="og:description" content="2024-05-24 更新：由於 ONNX QNN EP 文件更新很多，因此文章因應而大幅更新。 背景 由於最近生成式 AI 的興起，如 ChatGPT 與 DALL·E，微軟攜手廠商們 …"/>
<meta property="og:locale" content="en_US"/>
<meta property="og:url" content="https://yaticl.github.io/image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-QNN.html"/>
<meta property="og:type" content="article"/>
<meta property="article:published_time" content="2024-01-24 16:00:00+08:00"/>
<meta property="article:modified_time" content=""/>
<meta property="article:author" content="https://yaticl.github.io/author/ya-ti.html">
<meta property="article:section" content="Machine Learning"/>
<meta property="article:tag" content="Machine Learning"/>
<meta property="article:tag" content="AI"/>
<meta property="article:tag" content="ONNX"/>
<meta property="article:tag" content="DirectML"/>
<meta property="article:tag" content="ARM64"/>
<meta property="og:image" content="https://yaticl.github.io/images/profile.jpg">

  <title>Ya-Ti's Blog &ndash; 使用 ONNX Runtime 與 Qualcomm QNN 加速影像分類模型推理</title>

  <style>
    a {color: #0078D7;}
    a:hover {color: #0063B1;}
    a.btn {background-color: #0078D7;}
    a.btn:hover {
                  color: white;
                  background-color: #0063B1;
                }
    .tag-cloud a {
                    background-color: #0078D7;
                    padding: .2em .6em .2em;
                    font-size: .74em;
                    line-height: 1;
                    color: white;
                    text-align: center;
                    white-space: nowrap;
                    vertical-align: baseline;
                    border-radius: .25em;
                  }

    .tag-cloud a:hover {background-color: #0063B1;}
  </style>
</head>
<body class="light-theme">
  <aside>
    <div>
      <a href="https://yaticl.github.io">
        <img src="https://yaticl.github.io/images/profile.jpg" alt="" title="">
      </a>

      <h1>
        <a href="https://yaticl.github.io"></a>
      </h1>


        <form class="navbar-search" action="/search.html" role="search">
          <input type="text" name="q" id="tipue_search_input" placeholder="搜尋...">
        </form>

      <nav>
        <ul class="list">


              <li>
                <a target="_self"
                   href="https://yaticl.github.io/pages/about.html#about">
                  關於我
                </a>
              </li>

        </ul>
      </nav>

      <ul class="social">
          <li>
            <a  class="sc-github" href="https://github.com/yaticl/MyNotebooks" target="_blank">
              <i class="fab fa-github"></i>
            </a>
          </li>
          <li>
            <a  class="sc-rss" href="https://yaticl.github.io/feeds/all.atom.xml" target="_blank">
              <i class="fas fa-rss"></i>
            </a>
          </li>
      </ul>
    </div>

  </aside>
  <main>

    <nav>
      <a href="https://yaticl.github.io">Home</a>

      <a href="/categories.html">Categories</a>
      <a href="/tags.html">Tags</a>

      <a href="https://yaticl.github.io/feeds/all.atom.xml">Atom</a>

    </nav>

<article class="single">
  <header>
      
    <h1 id="image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-QNN">使用 ONNX Runtime 與 Qualcomm QNN 加速影像分類模型推理</h1>
    <p>
      Posted on Wed 24 January 2024 in <a href="https://yaticl.github.io/category/machine-learning.html">Machine Learning</a>

    </p>
  </header>


  <div>
    <p><strong>2024-05-24 更新：由於 ONNX QNN EP 文件更新很多，因此文章因應而大幅更新。</strong></p>
<h2 id="_1">背景</h2>
<p>由於最近生成式 AI 的興起，如 ChatGPT 與 DALL·E，微軟攜手廠商們開始推廣 AI PC，Intel、AMD 與高通等廠商，開始直接在處理器當中內建 Neural Processing Unit (NPU) 來加速 AI 模型的推理，且相較於在 GPU 推理有著更低的功耗。
在之前的<a href="https://yaticl.github.io/image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-directML.html">測試</a>中，實現了使用 ONNX Runtime 與 DirectML 實現對影像分類器的加速推理，這裡想嘗試使用基於 NPU 的推理加速。</p>
<h2 id="onnx-runtime">ONNX Runtime</h2>
<p><a href="https://onnxruntime.ai/">ONNX Runtime</a> 是一種跨平台的 AI 加速框架，支援主流的作業系統與程式語言，以及主流的深度學習框架所訓練出來的模型，如 PyTorch 與 TensorFlow。
ONNX 支援多種的加速方式 (Execution Providers, EP)，常見的像是 CPU, CUDA, DirectML 等等，最近也加入各家廠商的 NPU 支援，其餘的 EP 與細節可以參考官方的<a href="https://onnxruntime.ai/docs/execution-providers/">文件</a>。
這裡以 <a href="https://onnxruntime.ai/docs/execution-providers/QNN-ExecutionProvider.html">Qualcomm - QNN</a> 來嘗試實作，它使用 Qualcomm AI Engine Direct SDK (QNN SDK) 作為 ONNX Runtime 的後端。
根據文件，目前在 Qualcomm SC8280X 與 SM8350 兩款晶片 建置與測試，對應的行銷用型號應為 Snapdragon 8cx Gen 3 與 Snapdragon 888，這裡的測試平台是 Microsoft SQ3 ( 微軟客製化的 Snapdragon 8cx Gen 3)。</p>
<h2 id="_2">實作</h2>
<p>這裡嘗試用官方的 ResNet50 C# <a href="https://onnxruntime.ai/docs/tutorials/csharp/resnet50_csharp.html">範例</a>為基礎來實作。
由於範例的文件比較舊，我做了一些修改以適用最新版本的 ONNX 與執行環境。</p>
<h3 id="_3">環境準備</h3>
<ol>
<li>安裝 <a href="https://apps.microsoft.com/detail/XPDCFJDKLZJLP8">Visual Studio 2022 (VS)</a> 或更新的版本。</li>
<li>在 VS 中創建一個 C# Console App，.NET 版本選擇 6.0 或更高。</li>
<li>在方案的相依性安裝支援 QNN 的 <a href="https://www.nuget.org/packages/Microsoft.ML.OnnxRuntime.QNN/1.18.0?_src=template">ONNX Runtime</a>。</li>
<li>安裝前處理用的<a href="https://www.nuget.org/packages/SixLabors.ImageSharp/3.1.2?_src=template">相依性</a>。</li>
<li>下載 ONNX 模型<a href="https://github.com/onnx/models/blob/main/validated/vision/classification/resnet/model/resnet50-v1-12.onnx">檔案</a>( 提醒：為了要能用 NPU 來推理，模型檔案的 Opset version 需要大於等於 11)</li>
<li>下載一張待推理的<a href="https://github.com/microsoft/onnxruntime/blob/main/csharp/sample/Microsoft.ML.OnnxRuntime.ResNet50v2Sample/dog.jpeg">影像</a>，或其他影像。</li>
<li>準備一個有安裝 <a href="https://pypi.org/project/onnxruntime-qnn/"><code>onnxruntime-qnn</code></a> 的 Python 環境。</li>
</ol>
<h3 id="_4">前處理</h3>
<h4 id="_5">固定輸入的形狀</h4>
<p>由於要使用 QNN EP 存在一些限制，第一個是 QNN 不支援動態的 batch size 輸入，因此需要將模型的輸入 shape 固定成 1，ONNX 有提供<a href="https://onnxruntime.ai/docs/tutorials/mobile/helpers/make-dynamic-shape-fixed.html">工具</a>來將輸入的形狀改成固定。
首先利用 <a href="https://netron.app/">Netron</a> 找出模型的輸入名稱與形狀，以這裡用的模型為例：</p>
<p><img alt="Netron" src="https://onedrive.live.com/embed?resid=AC6F83C0AB8F9E1%211648576&amp;authkey=%21ACDftOgaLSTo_I8&amp;width=660"></p>
<p>輸入名稱是 <code>data</code>，batch size 是 <code>N</code>，我們要將 <code>N</code> 改成 <code>1</code>，轉換工具的用法如下：</p>
<div class="highlight"><pre><span></span><code><span class="n">python</span><span class="w"> </span><span class="o">-</span><span class="n">m</span><span class="w"> </span><span class="n">onnxruntime</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">make_dynamic_shape_fixed</span><span class="w"> </span><span class="o">--</span><span class="n">dim_param</span><span class="w"> </span><span class="n">N</span><span class="w"> </span><span class="o">--</span><span class="n">dim_value</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="n">resnet50</span><span class="o">-</span><span class="n">v1</span><span class="o">-</span><span class="mf">12.</span><span class="n">onnx</span><span class="w"> </span><span class="n">resnet50</span><span class="o">-</span><span class="n">v1</span><span class="o">-</span><span class="mf">12.</span><span class="n">fixed</span><span class="o">.</span><span class="n">onnx</span>
</code></pre></div>

<p>轉換完成之後可以再用 Netron 確認是否已經成功修改。</p>
<h4 id="model-quantization">模型量化 (Model quantization)</h4>
<p>由於 NPU 只接受量化過的模型，可能需要將模型做量化，參考網頁的<a href="https://github.com/microsoft/onnxruntime-inference-examples/tree/main/quantization/image_classification/cpu">範例</a>，需要準備校正用的資料來做模型量化，經過修改之後，在這個例子的讀檔案實現如下：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># resnet50_data_reader.py</span>

<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">onnxruntime</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">onnxruntime.quantization</span> <span class="kn">import</span> <span class="n">CalibrationDataReader</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>


<span class="k">def</span> <span class="nf">_preprocess_images</span><span class="p">(</span><span class="n">images_folder</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">height</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">width</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">size_limit</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads a batch of images and preprocess them</span>
<span class="sd">    parameter images_folder: path to folder storing images</span>
<span class="sd">    parameter height: image height in pixels</span>
<span class="sd">    parameter width: image width in pixels</span>
<span class="sd">    parameter size_limit: number of images to load. Default is 0 which means all images are picked.</span>
<span class="sd">    return: list of matrices characterizing multiple images</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">image_names</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">images_folder</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">size_limit</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">image_names</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">size_limit</span><span class="p">:</span>
        <span class="n">batch_filenames</span> <span class="o">=</span> <span class="p">[</span><span class="n">image_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">size_limit</span><span class="p">)]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch_filenames</span> <span class="o">=</span> <span class="n">image_names</span>
    <span class="n">unconcatenated_batch_data</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">image_name</span> <span class="ow">in</span> <span class="n">batch_filenames</span><span class="p">:</span>
        <span class="n">image_filepath</span> <span class="o">=</span> <span class="n">images_folder</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">image_name</span>
        <span class="n">pillow_img</span> <span class="o">=</span> <span class="n">Image</span><span class="o">.</span><span class="n">new</span><span class="p">(</span><span class="s2">&quot;RGB&quot;</span><span class="p">,</span> <span class="p">(</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">))</span>
        <span class="n">pillow_img</span><span class="o">.</span><span class="n">paste</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">image_filepath</span><span class="p">)</span><span class="o">.</span><span class="n">resize</span><span class="p">((</span><span class="n">width</span><span class="p">,</span> <span class="n">height</span><span class="p">)))</span>
        <span class="n">input_data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">pillow_img</span><span class="p">)</span> <span class="o">-</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
            <span class="p">[</span><span class="mf">123.68</span><span class="p">,</span> <span class="mf">116.78</span><span class="p">,</span> <span class="mf">103.94</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">numpy</span><span class="o">.</span><span class="n">float32</span>
        <span class="p">)</span>
        <span class="n">nhwc_data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">input_data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">nchw_data</span> <span class="o">=</span> <span class="n">nhwc_data</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># ONNX Runtime standard</span>
        <span class="n">unconcatenated_batch_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nchw_data</span><span class="p">)</span>
    <span class="n">batch_data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span>
        <span class="n">numpy</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">unconcatenated_batch_data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span>
    <span class="p">)</span>
    <span class="k">return</span> <span class="n">batch_data</span>


<span class="k">class</span> <span class="nc">ResNet50DataReader</span><span class="p">(</span><span class="n">CalibrationDataReader</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">calibration_image_folder</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enum_data</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># Use inference session to get input shape.</span>
        <span class="n">session</span> <span class="o">=</span> <span class="n">onnxruntime</span><span class="o">.</span><span class="n">InferenceSession</span><span class="p">(</span><span class="n">model_path</span><span class="p">,</span> <span class="n">providers</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;CPUExecutionProvider&#39;</span><span class="p">])</span>
        <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">)</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1"># Convert image to input data</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nhwc_data_list</span> <span class="o">=</span> <span class="n">_preprocess_images</span><span class="p">(</span>
            <span class="n">calibration_image_folder</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">size_limit</span><span class="o">=</span><span class="mi">0</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_name</span> <span class="o">=</span> <span class="n">session</span><span class="o">.</span><span class="n">get_inputs</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">datasize</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">nhwc_data_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_next</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">enum_data</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">enum_data</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span>
                <span class="p">[{</span><span class="bp">self</span><span class="o">.</span><span class="n">input_name</span><span class="p">:</span> <span class="n">nhwc_data</span><span class="p">}</span> <span class="k">for</span> <span class="n">nhwc_data</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">nhwc_data_list</span><span class="p">]</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">enum_data</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">rewind</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">enum_data</span> <span class="o">=</span> <span class="kc">None</span>
</code></pre></div>

<p>量化模型用的程式碼如下：</p>
<div class="highlight"><pre><span></span><code><span class="c1"># quantize_model.py</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">onnx</span>
<span class="kn">from</span> <span class="nn">resnet50_data_reader</span> <span class="kn">import</span> <span class="n">ResNet50DataReader</span>
<span class="kn">from</span> <span class="nn">onnxruntime.quantization</span> <span class="kn">import</span> <span class="n">QuantType</span><span class="p">,</span> <span class="n">quantize</span>
<span class="kn">from</span> <span class="nn">onnxruntime.quantization.execution_providers.qnn</span> <span class="kn">import</span> <span class="n">get_qnn_qdq_config</span><span class="p">,</span> <span class="n">qnn_preprocess_model</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">input_model_path</span> <span class="o">=</span> <span class="s2">&quot;resnet50-v1-12.fixed.onnx&quot;</span>  <span class="c1"># Replace with your actual model</span>
    <span class="n">output_model_path</span> <span class="o">=</span> <span class="s2">&quot;resnet50-v1-12.qdq.onnx&quot;</span>  <span class="c1"># Name of final quantized model</span>
    <span class="n">calibration_image_folder</span> <span class="o">=</span> <span class="s2">&quot;test_images&quot;</span> <span class="c1"># Path to calibration data</span>
    <span class="n">my_data_reader</span> <span class="o">=</span> <span class="n">ResNet50DataReader</span><span class="p">(</span><span class="n">calibration_image_folder</span><span class="p">,</span> <span class="n">input_model_path</span><span class="p">)</span>

    <span class="c1"># Pre-process the original float32 model.</span>
    <span class="n">preproc_model_path</span> <span class="o">=</span> <span class="s2">&quot;model.preproc.onnx&quot;</span>
    <span class="n">model_changed</span> <span class="o">=</span> <span class="n">qnn_preprocess_model</span><span class="p">(</span><span class="n">input_model_path</span><span class="p">,</span> <span class="n">preproc_model_path</span><span class="p">)</span>
    <span class="n">model_to_quantize</span> <span class="o">=</span> <span class="n">preproc_model_path</span> <span class="k">if</span> <span class="n">model_changed</span> <span class="k">else</span> <span class="n">input_model_path</span>

    <span class="c1"># Generate a suitable quantization configuration for this model.</span>
    <span class="c1"># Note that we&#39;re choosing to use uint16 activations and uint8 weights.</span>
    <span class="n">qnn_config</span> <span class="o">=</span> <span class="n">get_qnn_qdq_config</span><span class="p">(</span><span class="n">model_to_quantize</span><span class="p">,</span>
                                    <span class="n">my_data_reader</span><span class="p">,</span>
                                    <span class="n">activation_type</span><span class="o">=</span><span class="n">QuantType</span><span class="o">.</span><span class="n">QUInt16</span><span class="p">,</span>  <span class="c1"># uint16 activations</span>
                                    <span class="n">weight_type</span><span class="o">=</span><span class="n">QuantType</span><span class="o">.</span><span class="n">QUInt8</span><span class="p">)</span>       <span class="c1"># uint8 weights</span>

    <span class="c1"># Quantize the model.</span>
    <span class="n">quantize</span><span class="p">(</span><span class="n">model_to_quantize</span><span class="p">,</span> <span class="n">output_model_path</span><span class="p">,</span> <span class="n">qnn_config</span><span class="p">)</span>
</code></pre></div>

<p>執行 <code>quantize_model.py</code> 後就可以得到量化後的模型 <code>resnet50-v1-12.qdq.onnx</code>。</p>
<h3 id="_6">推理程式碼</h3>
<ol>
<li>先準備分類<a href="https://github.com/microsoft/onnxruntime/blob/main/csharp/sample/Microsoft.ML.OnnxRuntime.ResNet50v2Sample/LabelMap.cs">標籤</a>。</li>
<li>主程式 <code>Program.cs</code>：</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="k">using</span><span class="w"> </span><span class="nn">System</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="nn">System.Collections.Generic</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="nn">System.Linq</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="nn">Microsoft.ML.OnnxRuntime.Tensors</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="nn">SixLabors.ImageSharp</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="nn">SixLabors.ImageSharp.PixelFormats</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="nn">SixLabors.ImageSharp.Processing</span><span class="p">;</span>
<span class="k">using</span><span class="w"> </span><span class="nn">static</span><span class="w"> </span><span class="n">System</span><span class="p">.</span><span class="n">Net</span><span class="p">.</span><span class="n">Mime</span><span class="p">.</span><span class="n">MediaTypeNames</span><span class="p">;</span>

<span class="k">namespace</span><span class="w"> </span><span class="nn">Microsoft.ML.OnnxRuntime.ResNet50v2Sample</span>
<span class="p">{</span><span class="w">   </span>
<span class="w">    </span><span class="k">class</span><span class="w"> </span><span class="nc">Program</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">        </span><span class="k">public</span><span class="w"> </span><span class="k">static</span><span class="w"> </span><span class="k">void</span><span class="w"> </span><span class="nf">Main</span><span class="p">(</span><span class="kt">string</span><span class="p">[]</span><span class="w"> </span><span class="n">args</span><span class="p">)</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">            </span><span class="c1">// Read paths</span>
<span class="w">            </span><span class="kt">string</span><span class="w"> </span><span class="n">modelFilePath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Path\\to\\model\\resnet50-v1-12.qdq.onnx&quot;</span><span class="p">;</span>
<span class="w">            </span><span class="kt">string</span><span class="w"> </span><span class="n">imageFilePath</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Path\\to\\image\\dog.jpeg&quot;</span><span class="p">;</span>

<span class="w">            </span><span class="c1">// Read image</span>
<span class="w">            </span><span class="k">using</span><span class="w"> </span><span class="nn">Image</span><span class="o">&lt;</span><span class="n">Rgb24</span><span class="o">&gt;</span><span class="w"> </span><span class="n">image</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">SixLabors</span><span class="p">.</span><span class="n">ImageSharp</span><span class="p">.</span><span class="n">Image</span><span class="p">.</span><span class="n">Load</span><span class="o">&lt;</span><span class="n">Rgb24</span><span class="o">&gt;</span><span class="p">(</span><span class="n">imageFilePath</span><span class="p">);</span>

<span class="w">            </span><span class="c1">// Resize image</span>
<span class="w">            </span><span class="n">image</span><span class="p">.</span><span class="n">Mutate</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=&gt;</span>
<span class="w">            </span><span class="p">{</span>
<span class="w">                </span><span class="n">x</span><span class="p">.</span><span class="n">Resize</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">ResizeOptions</span>
<span class="w">                </span><span class="p">{</span>
<span class="w">                    </span><span class="n">Size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Size</span><span class="p">(</span><span class="m">224</span><span class="p">,</span><span class="w"> </span><span class="m">224</span><span class="p">),</span>
<span class="w">                    </span><span class="n">Mode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">ResizeMode</span><span class="p">.</span><span class="n">Crop</span>
<span class="w">                </span><span class="p">});</span>
<span class="w">            </span><span class="p">});</span>

<span class="w">            </span><span class="c1">// Preprocess image</span>
<span class="w">            </span><span class="n">Tensor</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">input</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">DenseTensor</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">(</span><span class="k">new</span><span class="p">[]</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="m">3</span><span class="p">,</span><span class="w"> </span><span class="m">224</span><span class="p">,</span><span class="w"> </span><span class="m">224</span><span class="w"> </span><span class="p">});</span>
<span class="w">            </span><span class="kt">var</span><span class="w"> </span><span class="n">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="p">[]</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="m">0.485f</span><span class="p">,</span><span class="w"> </span><span class="m">0.456f</span><span class="p">,</span><span class="w"> </span><span class="m">0.406f</span><span class="w"> </span><span class="p">};</span>
<span class="w">            </span><span class="kt">var</span><span class="w"> </span><span class="n">stddev</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="p">[]</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="m">0.229f</span><span class="p">,</span><span class="w"> </span><span class="m">0.224f</span><span class="p">,</span><span class="w"> </span><span class="m">0.225f</span><span class="w"> </span><span class="p">};</span>
<span class="w">            </span><span class="n">image</span><span class="p">.</span><span class="n">ProcessPixelRows</span><span class="p">(</span><span class="n">accessor</span><span class="w"> </span><span class="o">=&gt;</span>
<span class="w">            </span><span class="p">{</span>
<span class="w">                </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">;</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">accessor</span><span class="p">.</span><span class="n">Height</span><span class="p">;</span><span class="w"> </span><span class="n">y</span><span class="o">++</span><span class="p">)</span>
<span class="w">                </span><span class="p">{</span>
<span class="w">                    </span><span class="n">Span</span><span class="o">&lt;</span><span class="n">Rgb24</span><span class="o">&gt;</span><span class="w"> </span><span class="n">pixelSpan</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">accessor</span><span class="p">.</span><span class="n">GetRowSpan</span><span class="p">(</span><span class="n">y</span><span class="p">);</span>
<span class="w">                    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="kt">int</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">0</span><span class="p">;</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">accessor</span><span class="p">.</span><span class="n">Width</span><span class="p">;</span><span class="w"> </span><span class="n">x</span><span class="o">++</span><span class="p">)</span>
<span class="w">                    </span><span class="p">{</span>
<span class="w">                        </span><span class="n">input</span><span class="p">[</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">pixelSpan</span><span class="p">[</span><span class="n">x</span><span class="p">].</span><span class="n">R</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">255f</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mean</span><span class="p">[</span><span class="m">0</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stddev</span><span class="p">[</span><span class="m">0</span><span class="p">];</span>
<span class="w">                        </span><span class="n">input</span><span class="p">[</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">pixelSpan</span><span class="p">[</span><span class="n">x</span><span class="p">].</span><span class="n">G</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">255f</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mean</span><span class="p">[</span><span class="m">1</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stddev</span><span class="p">[</span><span class="m">1</span><span class="p">];</span>
<span class="w">                        </span><span class="n">input</span><span class="p">[</span><span class="m">0</span><span class="p">,</span><span class="w"> </span><span class="m">2</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">x</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">((</span><span class="n">pixelSpan</span><span class="p">[</span><span class="n">x</span><span class="p">].</span><span class="n">B</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">255f</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">mean</span><span class="p">[</span><span class="m">2</span><span class="p">])</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">stddev</span><span class="p">[</span><span class="m">2</span><span class="p">];</span>
<span class="w">                    </span><span class="p">}</span>
<span class="w">                </span><span class="p">}</span>
<span class="w">            </span><span class="p">});</span>

<span class="w">            </span><span class="c1">// Setup inputs</span>
<span class="w">            </span><span class="kt">var</span><span class="w"> </span><span class="n">inputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">List</span><span class="o">&lt;</span><span class="n">NamedOnnxValue</span><span class="o">&gt;</span>
<span class="w">            </span><span class="p">{</span>
<span class="w">                </span><span class="n">NamedOnnxValue</span><span class="p">.</span><span class="n">CreateFromTensor</span><span class="p">(</span><span class="s">&quot;data&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">input</span><span class="p">)</span>
<span class="w">            </span><span class="p">};</span>

<span class="w">            </span><span class="c1">// Run inference</span>
<span class="w">            </span><span class="n">Dictionary</span><span class="o">&lt;</span><span class="kt">string</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="o">&gt;</span><span class="w"> </span><span class="n">qnn_options</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Dictionary</span><span class="o">&lt;</span><span class="kt">string</span><span class="p">,</span><span class="w"> </span><span class="kt">string</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">            </span><span class="n">qnn_options</span><span class="p">.</span><span class="n">Add</span><span class="p">(</span><span class="s">&quot;backend_path&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;QnnHtp.dll&quot;</span><span class="p">);</span><span class="w"> </span><span class="c1">//&quot;QnnHtp.dll&quot; for NPU or &quot;QnnCpu.dll&quot; for CPU</span>
<span class="w">            </span><span class="k">using</span><span class="w"> </span><span class="nn">var</span><span class="w"> </span><span class="n">session_options</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">SessionOptions</span><span class="p">();</span>
<span class="w">            </span><span class="n">session_options</span><span class="p">.</span><span class="n">AppendExecutionProvider</span><span class="p">(</span><span class="s">&quot;QNN&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">qnn_options</span><span class="p">);</span>
<span class="p">;</span>
<span class="w">            </span><span class="k">using</span><span class="w"> </span><span class="nn">var</span><span class="w"> </span><span class="n">session</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">InferenceSession</span><span class="p">(</span><span class="n">modelFilePath</span><span class="p">,</span><span class="w"> </span><span class="n">session_options</span><span class="p">);</span>
<span class="w">            </span><span class="k">using</span><span class="w"> </span><span class="nn">IDisposableReadOnlyCollection</span><span class="o">&lt;</span><span class="n">DisposableNamedOnnxValue</span><span class="o">&gt;</span><span class="w"> </span><span class="n">results</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">session</span><span class="p">.</span><span class="n">Run</span><span class="p">(</span><span class="n">inputs</span><span class="p">);</span>

<span class="w">            </span><span class="c1">// Postprocess to get softmax vector</span>
<span class="w">            </span><span class="n">IEnumerable</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">results</span><span class="p">.</span><span class="n">First</span><span class="p">().</span><span class="n">AsEnumerable</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="p">();</span>
<span class="w">            </span><span class="kt">float</span><span class="w"> </span><span class="n">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">Sum</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">Math</span><span class="p">.</span><span class="n">Exp</span><span class="p">(</span><span class="n">x</span><span class="p">));</span>
<span class="w">            </span><span class="n">IEnumerable</span><span class="o">&lt;</span><span class="kt">float</span><span class="o">&gt;</span><span class="w"> </span><span class="n">softmax</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">output</span><span class="p">.</span><span class="n">Select</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="p">(</span><span class="kt">float</span><span class="p">)</span><span class="n">Math</span><span class="p">.</span><span class="n">Exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="n">sum</span><span class="p">);</span>

<span class="w">            </span><span class="c1">// Extract top 10 predicted classes</span>
<span class="w">            </span><span class="n">IEnumerable</span><span class="o">&lt;</span><span class="n">Prediction</span><span class="o">&gt;</span><span class="w"> </span><span class="n">top10</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">softmax</span><span class="p">.</span><span class="n">Select</span><span class="p">((</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">Prediction</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="n">Label</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">LabelMap</span><span class="p">.</span><span class="n">Labels</span><span class="p">[</span><span class="n">i</span><span class="p">],</span><span class="w"> </span><span class="n">Confidence</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">x</span><span class="w"> </span><span class="p">})</span>
<span class="w">                               </span><span class="p">.</span><span class="n">OrderByDescending</span><span class="p">(</span><span class="n">x</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">x</span><span class="p">.</span><span class="n">Confidence</span><span class="p">)</span>
<span class="w">                               </span><span class="p">.</span><span class="n">Take</span><span class="p">(</span><span class="m">10</span><span class="p">);</span>

<span class="w">            </span><span class="c1">// Print results to console</span>
<span class="w">            </span><span class="n">Console</span><span class="p">.</span><span class="n">WriteLine</span><span class="p">(</span><span class="s">&quot;Top 10 predictions for ResNet50 v2...&quot;</span><span class="p">);</span>
<span class="w">            </span><span class="n">Console</span><span class="p">.</span><span class="n">WriteLine</span><span class="p">(</span><span class="s">&quot;--------------------------------------------------------------&quot;</span><span class="p">);</span>
<span class="w">            </span><span class="k">foreach</span><span class="w"> </span><span class="p">(</span><span class="kt">var</span><span class="w"> </span><span class="n">t</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">top10</span><span class="p">)</span>
<span class="w">            </span><span class="p">{</span>
<span class="w">                </span><span class="n">Console</span><span class="p">.</span><span class="n">WriteLine</span><span class="p">(</span><span class="s">$&quot;Label: {t.Label}, Confidence: {t.Confidence}&quot;</span><span class="p">);</span>
<span class="w">            </span><span class="p">}</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="p">}</span>
</code></pre></div>

<p>首先使用 <code>QnnCpu.dll</code> 來測試推理 <code>resnet50-v1-12.fixed.onnx</code>，輸出結果範例：</p>
<div class="highlight"><pre><span></span><code>Error in cpuinfo: Unknown chip model name &#39;Microsoft SQ3&#39;.
Please add new Windows on Arm SoC/chip support to arm/windows/init.c!
unknown ARM CPU part 0xd4b ignored
unknown ARM CPU part 0xd4b ignored
unknown ARM CPU part 0xd4b ignored
unknown ARM CPU part 0xd4b ignored
unknown ARM CPU part 0xd4c ignored
unknown ARM CPU part 0xd4c ignored
unknown ARM CPU part 0xd4c ignored
unknown ARM CPU part 0xd4c ignored
Top 10 predictions...
--------------------------------------------------------------
Label: Golden Retriever, Confidence: 0.8330527
Label: Kuvasz, Confidence: 0.058261674
Label: Saluki, Confidence: 0.052930113
Label: Flat-Coated Retriever, Confidence: 0.005992945
Label: English Setter, Confidence: 0.0042325333
Label: Afghan Hound, Confidence: 0.0037076203
Label: Irish Setter, Confidence: 0.0036869524
Label: Clumber Spaniel, Confidence: 0.003038115
Label: Curly-coated Retriever, Confidence: 0.003019722
Label: Sussex Spaniel, Confidence: 0.0028180785
</code></pre></div>

<p>ONNX Runtime 提示無法辨識處理器型號，但依然可以正確地執行。</p>
<p>不幸地，當後端指定為 <code>QnnHtp.dll</code> 時，卻回報 runtime error，無法正常執行，看起來是跑 BatchNormalization 運算時出現錯誤：</p>
<div class="highlight"><pre><span></span><code><span class="nx">Microsoft</span><span class="p">.</span><span class="nx">ML</span><span class="p">.</span><span class="nx">OnnxRuntime</span><span class="p">.</span><span class="nx">OnnxRuntimeException</span>
<span class="w">  </span><span class="nx">HResult</span><span class="p">=</span><span class="mh">0x80131500</span>
<span class="w">  </span><span class="nx">Message</span><span class="p">=[</span><span class="nx">ErrorCode</span><span class="p">:</span><span class="nx">Fail</span><span class="p">]</span><span class="w"> </span><span class="nx">Node</span><span class="w"> </span><span class="err">&#39;</span><span class="nx">BatchNormalization</span><span class="err">&#39;</span><span class="w"> </span><span class="nx">OpType</span><span class="p">:</span><span class="nx">BatchNormalization</span><span class="w"> </span><span class="nx">with</span><span class="w"> </span><span class="nx">domain</span><span class="p">:</span><span class="nx">com</span><span class="p">.</span><span class="nx">ms</span><span class="p">.</span><span class="nx">internal</span><span class="p">.</span><span class="nx">nhwc</span><span class="w"> </span><span class="nx">was</span><span class="w"> </span><span class="nx">inserted</span><span class="w"> </span><span class="nx">using</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">NHWC</span><span class="w"> </span><span class="nx">format</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nx">requested</span><span class="w"> </span><span class="nx">by</span><span class="w"> </span><span class="nx">QNNExecutionProvider</span><span class="p">,</span><span class="w"> </span><span class="nx">but</span><span class="w"> </span><span class="nx">was</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="nx">selected</span><span class="w"> </span><span class="nx">by</span><span class="w"> </span><span class="nx">that</span><span class="w"> </span><span class="nx">EP</span><span class="p">.</span><span class="w"> </span><span class="nx">This</span><span class="w"> </span><span class="nx">means</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">graph</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="nx">now</span><span class="w"> </span><span class="nx">invalid</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nx">there</span><span class="w"> </span><span class="nx">will</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="nx">be</span><span class="w"> </span><span class="nx">an</span><span class="w"> </span><span class="nx">EP</span><span class="w"> </span><span class="nx">able</span><span class="w"> </span><span class="nx">to</span><span class="w"> </span><span class="nx">run</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">node</span><span class="p">.</span><span class="w"> </span><span class="nx">This</span><span class="w"> </span><span class="nx">could</span><span class="w"> </span><span class="nx">be</span><span class="w"> </span><span class="nx">a</span><span class="w"> </span><span class="nx">bug</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">layout</span><span class="w"> </span><span class="nx">transformer</span><span class="p">,</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">GetCapability</span><span class="w"> </span><span class="nx">implementation</span><span class="w"> </span><span class="nx">of</span><span class="w"> </span><span class="nx">the</span><span class="w"> </span><span class="nx">EP</span><span class="p">.</span>
<span class="w">  </span><span class="nx">Source</span><span class="p">=</span><span class="nx">Microsoft</span><span class="p">.</span><span class="nx">ML</span><span class="p">.</span><span class="nx">OnnxRuntime</span>
<span class="w">  </span><span class="nx">StackTrace</span><span class="p">:</span>
<span class="w">   </span><span class="nx">at</span><span class="w"> </span><span class="nx">Microsoft</span><span class="p">.</span><span class="nx">ML</span><span class="p">.</span><span class="nx">OnnxRuntime</span><span class="p">.</span><span class="nx">NativeApiStatus</span><span class="p">.</span><span class="nx">VerifySuccess</span><span class="p">(</span><span class="nx">IntPtr</span><span class="w"> </span><span class="nx">nativeStatus</span><span class="p">)</span>
<span class="w">   </span><span class="nx">at</span><span class="w"> </span><span class="nx">Microsoft</span><span class="p">.</span><span class="nx">ML</span><span class="p">.</span><span class="nx">OnnxRuntime</span><span class="p">.</span><span class="nx">InferenceSession</span><span class="p">.</span><span class="nx">Init</span><span class="p">(</span><span class="nx">String</span><span class="w"> </span><span class="nx">modelPath</span><span class="p">,</span><span class="w"> </span><span class="nx">SessionOptions</span><span class="w"> </span><span class="nx">options</span><span class="p">,</span><span class="w"> </span><span class="nx">PrePackedWeightsContainer</span><span class="w"> </span><span class="nx">prepackedWeightsContainer</span><span class="p">)</span>
<span class="w">   </span><span class="nx">at</span><span class="w"> </span><span class="nx">Microsoft</span><span class="p">.</span><span class="nx">ML</span><span class="p">.</span><span class="nx">OnnxRuntime</span><span class="p">.</span><span class="nx">InferenceSession</span><span class="p">..</span><span class="nx">ctor</span><span class="p">(</span><span class="nx">String</span><span class="w"> </span><span class="nx">modelPath</span><span class="p">,</span><span class="w"> </span><span class="nx">SessionOptions</span><span class="w"> </span><span class="nx">options</span><span class="p">)</span>
<span class="w">   </span><span class="nx">at</span><span class="w"> </span><span class="nx">Microsoft</span><span class="p">.</span><span class="nx">ML</span><span class="p">.</span><span class="nx">OnnxRuntime</span><span class="p">.</span><span class="nx">ResNet50v2Sample</span><span class="p">.</span><span class="nx">Program</span><span class="p">.</span><span class="nx">Main</span><span class="p">(</span><span class="nx">String</span><span class="p">[]</span><span class="w"> </span><span class="nx">args</span><span class="p">)</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="nx">C</span><span class="p">:</span><span class="err">\</span><span class="nx">Users</span><span class="err">\</span><span class="nx">ya</span><span class="o">-</span><span class="nx">ti</span><span class="err">\</span><span class="nx">Repos</span><span class="err">\</span><span class="nx">ONNX_ResNet</span><span class="err">\</span><span class="nx">ONNX_ResNet</span><span class="err">\</span><span class="nx">Program</span><span class="p">.</span><span class="nx">cs</span><span class="p">:</span><span class="nx">line</span><span class="w"> </span><span class="mi">63</span>
</code></pre></div>

<p>由於 ResNet 無法順利地用 NPU 來推理，這裡嘗試換成另一個範例模型 <a href="https://github.com/onnx/models/blob/main/validated/vision/classification/mobilenet/model/mobilenetv2-12.onnx">MobileNet V2</a> 來測試。
經過前面所述的前處理後，將模型量化為 <code>mobilenetv2-12.qdq.onnx</code>，使用 <code>QnnHtp.dll</code> 執行的結果如下：</p>
<div class="highlight"><pre><span></span><code><span class="nv">Error</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">cpuinfo</span>:<span class="w"> </span><span class="nv">Unknown</span><span class="w"> </span><span class="nv">chip</span><span class="w"> </span><span class="nv">model</span><span class="w"> </span><span class="nv">name</span><span class="w"> </span><span class="s1">&#39;Microsoft SQ3&#39;</span>.
<span class="nv">Please</span><span class="w"> </span><span class="nv">add</span><span class="w"> </span><span class="nv">new</span><span class="w"> </span><span class="nv">Windows</span><span class="w"> </span><span class="nv">on</span><span class="w"> </span><span class="nv">Arm</span><span class="w"> </span><span class="nv">SoC</span><span class="o">/</span><span class="nv">chip</span><span class="w"> </span><span class="nv">support</span><span class="w"> </span><span class="nv">to</span><span class="w"> </span><span class="nv">arm</span><span class="o">/</span><span class="nv">windows</span><span class="o">/</span><span class="nv">init</span>.<span class="nv">c</span><span class="o">!</span>
<span class="nv">unknown</span><span class="w"> </span><span class="nv">ARM</span><span class="w"> </span><span class="nv">CPU</span><span class="w"> </span><span class="nv">part</span><span class="w"> </span><span class="mi">0</span><span class="nv">xd4b</span><span class="w"> </span><span class="nv">ignored</span>
<span class="nv">unknown</span><span class="w"> </span><span class="nv">ARM</span><span class="w"> </span><span class="nv">CPU</span><span class="w"> </span><span class="nv">part</span><span class="w"> </span><span class="mi">0</span><span class="nv">xd4b</span><span class="w"> </span><span class="nv">ignored</span>
<span class="nv">unknown</span><span class="w"> </span><span class="nv">ARM</span><span class="w"> </span><span class="nv">CPU</span><span class="w"> </span><span class="nv">part</span><span class="w"> </span><span class="mi">0</span><span class="nv">xd4b</span><span class="w"> </span><span class="nv">ignored</span>
<span class="nv">unknown</span><span class="w"> </span><span class="nv">ARM</span><span class="w"> </span><span class="nv">CPU</span><span class="w"> </span><span class="nv">part</span><span class="w"> </span><span class="mi">0</span><span class="nv">xd4b</span><span class="w"> </span><span class="nv">ignored</span>
<span class="nv">unknown</span><span class="w"> </span><span class="nv">ARM</span><span class="w"> </span><span class="nv">CPU</span><span class="w"> </span><span class="nv">part</span><span class="w"> </span><span class="mi">0</span><span class="nv">xd4c</span><span class="w"> </span><span class="nv">ignored</span>
<span class="nv">unknown</span><span class="w"> </span><span class="nv">ARM</span><span class="w"> </span><span class="nv">CPU</span><span class="w"> </span><span class="nv">part</span><span class="w"> </span><span class="mi">0</span><span class="nv">xd4c</span><span class="w"> </span><span class="nv">ignored</span>
<span class="nv">unknown</span><span class="w"> </span><span class="nv">ARM</span><span class="w"> </span><span class="nv">CPU</span><span class="w"> </span><span class="nv">part</span><span class="w"> </span><span class="mi">0</span><span class="nv">xd4c</span><span class="w"> </span><span class="nv">ignored</span>
<span class="nv">unknown</span><span class="w"> </span><span class="nv">ARM</span><span class="w"> </span><span class="nv">CPU</span><span class="w"> </span><span class="nv">part</span><span class="w"> </span><span class="mi">0</span><span class="nv">xd4c</span><span class="w"> </span><span class="nv">ignored</span>
<span class="nv">Starting</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Graph</span><span class="w"> </span><span class="nv">Preparation</span><span class="w"> </span><span class="nv">Initializing</span>
<span class="nv">Completed</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Graph</span><span class="w"> </span><span class="nv">Preparation</span><span class="w"> </span><span class="nv">Initializing</span><span class="w"> </span><span class="ss">(</span><span class="mi">1436</span><span class="w"> </span><span class="nv">us</span><span class="ss">)</span>
<span class="nv">Starting</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Graph</span><span class="w"> </span><span class="nv">Transformations</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="nv">Optimizations</span>
<span class="nv">Completed</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Graph</span><span class="w"> </span><span class="nv">Transformations</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="nv">Optimizations</span><span class="w"> </span><span class="ss">(</span><span class="mi">191067</span><span class="w"> </span><span class="nv">us</span><span class="ss">)</span>
<span class="nv">Starting</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Graph</span><span class="w"> </span><span class="nv">Sequencing</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">Target</span>
<span class="nv">Completed</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Graph</span><span class="w"> </span><span class="nv">Sequencing</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">Target</span><span class="w"> </span><span class="ss">(</span><span class="mi">31089</span><span class="w"> </span><span class="nv">us</span><span class="ss">)</span>
<span class="nv">Starting</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">VTCM</span><span class="w"> </span><span class="nv">Allocation</span>
<span class="nv">Completed</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">VTCM</span><span class="w"> </span><span class="nv">Allocation</span><span class="w"> </span><span class="ss">(</span><span class="mi">21108</span><span class="w"> </span><span class="nv">us</span><span class="ss">)</span>
<span class="nv">Starting</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Parallelization</span><span class="w"> </span><span class="nv">Optimization</span>
<span class="nv">Completed</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Parallelization</span><span class="w"> </span><span class="nv">Optimization</span><span class="w"> </span><span class="ss">(</span><span class="mi">3288</span><span class="w"> </span><span class="nv">us</span><span class="ss">)</span>
<span class="nv">Starting</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Finalizing</span><span class="w"> </span><span class="nv">Graph</span><span class="w"> </span><span class="nv">Sequence</span>
<span class="nv">Completed</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Finalizing</span><span class="w"> </span><span class="nv">Graph</span><span class="w"> </span><span class="nv">Sequence</span><span class="w"> </span><span class="ss">(</span><span class="mi">3288</span><span class="w"> </span><span class="nv">us</span><span class="ss">)</span>
<span class="nv">Starting</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Completion</span>
<span class="nv">Completed</span><span class="w"> </span><span class="nv">stage</span>:<span class="w"> </span><span class="nv">Completion</span><span class="w"> </span><span class="ss">(</span><span class="mi">217</span><span class="w"> </span><span class="nv">us</span><span class="ss">)</span>
<span class="nv">Top</span><span class="w"> </span><span class="mi">10</span><span class="w"> </span><span class="nv">predictions</span>...
<span class="o">--------------------------------------------------------------</span>
<span class="nv">Label</span>:<span class="w"> </span><span class="nv">Cocker</span><span class="w"> </span><span class="nv">Spaniels</span>,<span class="w"> </span><span class="nv">Confidence</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">47969297</span>
<span class="nv">Label</span>:<span class="w"> </span><span class="nv">Golden</span><span class="w"> </span><span class="nv">Retriever</span>,<span class="w"> </span><span class="nv">Confidence</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">1477721</span>
<span class="nv">Label</span>:<span class="w"> </span><span class="nv">Standard</span><span class="w"> </span><span class="nv">Poodle</span>,<span class="w"> </span><span class="nv">Confidence</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">08921216</span>
<span class="nv">Label</span>:<span class="w"> </span><span class="nv">Airedale</span><span class="w"> </span><span class="nv">Terrier</span>,<span class="w"> </span><span class="nv">Confidence</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">063725926</span>
<span class="nv">Label</span>:<span class="w"> </span><span class="nv">English</span><span class="w"> </span><span class="nv">Setter</span>,<span class="w"> </span><span class="nv">Confidence</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">045520637</span>
<span class="nv">Label</span>:<span class="w"> </span><span class="nv">Otterhound</span>,<span class="w"> </span><span class="nv">Confidence</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">03847344</span>
<span class="nv">Label</span>:<span class="w"> </span><span class="nv">Clumber</span><span class="w"> </span><span class="nv">Spaniel</span>,<span class="w"> </span><span class="nv">Confidence</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">03251625</span>
<span class="nv">Label</span>:<span class="w"> </span><span class="nv">Irish</span><span class="w"> </span><span class="nv">Setter</span>,<span class="w"> </span><span class="nv">Confidence</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">019631129</span>
<span class="nv">Label</span>:<span class="w"> </span><span class="nv">Miniature</span><span class="w"> </span><span class="nv">Poodle</span>,<span class="w"> </span><span class="nv">Confidence</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">016591465</span>
<span class="nv">Label</span>:<span class="w"> </span><span class="nv">Toy</span><span class="w"> </span><span class="nv">Poodle</span>,<span class="w"> </span><span class="nv">Confidence</span>:<span class="w"> </span><span class="mi">0</span>.<span class="mi">010016814</span>
</code></pre></div>

<p>成功地使用 NPU 來加速推理，Top 1 算出來的數值與用 CPU 差不多 (CPU: Label: Golden Retriever, Confidence: 0.43511143)。</p>
<p>ONNX 的 GitHub 也有上傳用標準 ONNX 量化的 <a href="https://github.com/onnx/models/blob/main/validated/vision/classification/mobilenet/model/mobilenetv2-12-qdq.onnx">MobileNet V2</a>，這裡也嘗試測試直接用 NPU 推理這個模型，部分輸出如下：</p>
<div class="highlight"><pre><span></span><code><span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">24</span><span class="w"> </span><span class="mi">13</span><span class="o">:</span><span class="mi">59</span><span class="o">:</span><span class="mf">17.9089996</span><span class="w"> </span><span class="err">[</span><span class="n">W</span><span class="o">:</span><span class="n">onnxruntime</span><span class="o">:</span><span class="p">,</span><span class="w"> </span><span class="n">qnn_model_wrapper</span><span class="p">.</span><span class="n">cc</span><span class="o">:</span><span class="mi">240</span><span class="w"> </span><span class="n">onnxruntime</span><span class="o">::</span><span class="n">qnn</span><span class="o">::</span><span class="n">QnnModelWrapper</span><span class="o">::</span><span class="n">CreateQnnNode</span><span class="err">]</span><span class="w"> </span><span class="n">QNN</span><span class="p">.</span><span class="n">backendValidateOpConfig</span><span class="p">()</span><span class="w"> </span><span class="n">failed</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">node</span><span class="w"> </span><span class="n n-Quoted">`Add_26`</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="k">type</span><span class="w"> </span><span class="n n-Quoted">`ElementWiseAdd`</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="k">error</span><span class="w"> </span><span class="k">code</span><span class="w"> </span><span class="mi">3110</span>

<span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">24</span><span class="w"> </span><span class="mi">13</span><span class="o">:</span><span class="mi">59</span><span class="o">:</span><span class="mf">17.9167208</span><span class="w"> </span><span class="err">[</span><span class="n">W</span><span class="o">:</span><span class="n">onnxruntime</span><span class="o">:</span><span class="p">,</span><span class="w"> </span><span class="n">qnn_execution_provider</span><span class="p">.</span><span class="n">cc</span><span class="o">:</span><span class="mi">364</span><span class="w"> </span><span class="n">onnxruntime</span><span class="o">::</span><span class="n">QNNExecutionProvider</span><span class="o">::</span><span class="n">IsNodeSupported</span><span class="err">]</span><span class="w"> </span><span class="k">Add</span><span class="w"> </span><span class="n">node</span><span class="w"> </span><span class="n n-Quoted">`Add_26`</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">supported</span><span class="o">:</span><span class="w"> </span><span class="n">base_op_builder</span><span class="p">.</span><span class="n">cc</span><span class="o">:</span><span class="mi">162</span><span class="w"> </span><span class="n">onnxruntime</span><span class="o">::</span><span class="n">qnn</span><span class="o">::</span><span class="n">BaseOpBuilder</span><span class="o">::</span><span class="n">ProcessOutputs</span><span class="w"> </span><span class="n">Failed</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="k">add</span><span class="w"> </span><span class="n">node</span><span class="p">.</span>

<span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">24</span><span class="w"> </span><span class="mi">13</span><span class="o">:</span><span class="mi">59</span><span class="o">:</span><span class="mf">18.2300141</span><span class="w"> </span><span class="err">[</span><span class="n">W</span><span class="o">:</span><span class="n">onnxruntime</span><span class="o">:</span><span class="p">,</span><span class="w"> </span><span class="n">qnn_execution_provider</span><span class="p">.</span><span class="n">cc</span><span class="o">:</span><span class="mi">364</span><span class="w"> </span><span class="n">onnxruntime</span><span class="o">::</span><span class="n">QNNExecutionProvider</span><span class="o">::</span><span class="n">IsNodeSupported</span><span class="err">]</span><span class="w"> </span><span class="k">Add</span><span class="w"> </span><span class="n">node</span><span class="w"> </span><span class="n n-Quoted">`Gemm_104_Add`</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">supported</span><span class="o">:</span><span class="w"> </span><span class="n">base_op_builder</span><span class="p">.</span><span class="n">cc</span><span class="o">:</span><span class="mi">162</span><span class="w"> </span><span class="n">onnxruntime</span><span class="o">::</span><span class="n">qnn</span><span class="o">::</span><span class="n">BaseOpBuilder</span><span class="o">::</span><span class="n">ProcessOutputs</span><span class="w"> </span><span class="n">Failed</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="k">add</span><span class="w"> </span><span class="n">node</span><span class="p">.</span>
<span class="k">Starting</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">Graph</span><span class="w"> </span><span class="n">Preparation</span><span class="w"> </span><span class="n">Initializing</span>
<span class="n">Completed</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">Graph</span><span class="w"> </span><span class="n">Preparation</span><span class="w"> </span><span class="n">Initializing</span><span class="w"> </span><span class="p">(</span><span class="mi">742</span><span class="w"> </span><span class="n">us</span><span class="p">)</span>
<span class="k">Starting</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">Graph</span><span class="w"> </span><span class="n">Transformations</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">Optimizations</span>
<span class="n">Completed</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">Graph</span><span class="w"> </span><span class="n">Transformations</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="n">Optimizations</span><span class="w"> </span><span class="p">(</span><span class="mi">30250</span><span class="w"> </span><span class="n">us</span><span class="p">)</span>
<span class="k">Starting</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">Graph</span><span class="w"> </span><span class="n">Sequencing</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">Target</span>
<span class="n">Completed</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">Graph</span><span class="w"> </span><span class="n">Sequencing</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">Target</span><span class="w"> </span><span class="p">(</span><span class="mi">6511</span><span class="w"> </span><span class="n">us</span><span class="p">)</span>
<span class="k">Starting</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">VTCM</span><span class="w"> </span><span class="n">Allocation</span>
<span class="n">Completed</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">VTCM</span><span class="w"> </span><span class="n">Allocation</span><span class="w"> </span><span class="p">(</span><span class="mi">4765</span><span class="w"> </span><span class="n">us</span><span class="p">)</span>
<span class="k">Starting</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">Parallelization</span><span class="w"> </span><span class="n">Optimization</span>
<span class="n">Completed</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">Parallelization</span><span class="w"> </span><span class="n">Optimization</span><span class="w"> </span><span class="p">(</span><span class="mi">697</span><span class="w"> </span><span class="n">us</span><span class="p">)</span>
<span class="k">Starting</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">Finalizing</span><span class="w"> </span><span class="n">Graph</span><span class="w"> </span><span class="n">Sequence</span>
<span class="n">Completed</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="n">Finalizing</span><span class="w"> </span><span class="n">Graph</span><span class="w"> </span><span class="n">Sequence</span><span class="w"> </span><span class="p">(</span><span class="mi">1064</span><span class="w"> </span><span class="n">us</span><span class="p">)</span>
<span class="k">Starting</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="k">Completion</span>
<span class="n">Completed</span><span class="w"> </span><span class="n">stage</span><span class="o">:</span><span class="w"> </span><span class="k">Completion</span><span class="w"> </span><span class="p">(</span><span class="mi">144</span><span class="w"> </span><span class="n">us</span><span class="p">)</span>
<span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">24</span><span class="w"> </span><span class="mi">13</span><span class="o">:</span><span class="mi">59</span><span class="o">:</span><span class="mf">18.6360876</span><span class="w"> </span><span class="err">[</span><span class="n">W</span><span class="o">:</span><span class="n">onnxruntime</span><span class="o">:</span><span class="p">,</span><span class="w"> </span><span class="n">session_state</span><span class="p">.</span><span class="n">cc</span><span class="o">:</span><span class="mi">1166</span><span class="w"> </span><span class="n">onnxruntime</span><span class="o">::</span><span class="n">VerifyEachNodeIsAssignedToAnEp</span><span class="err">]</span><span class="w"> </span><span class="k">Some</span><span class="w"> </span><span class="n">nodes</span><span class="w"> </span><span class="n">were</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">assigned</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">preferred</span><span class="w"> </span><span class="n">execution</span><span class="w"> </span><span class="n">providers</span><span class="w"> </span><span class="n">which</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">may</span><span class="w"> </span><span class="k">not</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">negative</span><span class="w"> </span><span class="n">impact</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">performance</span><span class="p">.</span><span class="w"> </span><span class="n">e</span><span class="p">.</span><span class="n">g</span><span class="p">.</span><span class="w"> </span><span class="n">ORT</span><span class="w"> </span><span class="n">explicitly</span><span class="w"> </span><span class="n">assigns</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="n">related</span><span class="w"> </span><span class="n">ops</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="k">CPU</span><span class="w"> </span><span class="k">to</span><span class="w"> </span><span class="n">improve</span><span class="w"> </span><span class="n">perf</span><span class="p">.</span>
<span class="mi">2024</span><span class="o">-</span><span class="mi">05</span><span class="o">-</span><span class="mi">24</span><span class="w"> </span><span class="mi">13</span><span class="o">:</span><span class="mi">59</span><span class="o">:</span><span class="mf">18.6589396</span><span class="w"> </span><span class="err">[</span><span class="n">W</span><span class="o">:</span><span class="n">onnxruntime</span><span class="o">:</span><span class="p">,</span><span class="w"> </span><span class="n">session_state</span><span class="p">.</span><span class="n">cc</span><span class="o">:</span><span class="mi">1168</span><span class="w"> </span><span class="n">onnxruntime</span><span class="o">::</span><span class="n">VerifyEachNodeIsAssignedToAnEp</span><span class="err">]</span><span class="w"> </span><span class="n">Rerunning</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">verbose</span><span class="w"> </span><span class="n">output</span><span class="w"> </span><span class="k">on</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">non</span><span class="o">-</span><span class="n">minimal</span><span class="w"> </span><span class="n">build</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="k">show</span><span class="w"> </span><span class="n">node</span><span class="w"> </span><span class="n">assignments</span><span class="p">.</span>
<span class="n">Top</span><span class="w"> </span><span class="mi">10</span><span class="w"> </span><span class="n">predictions</span><span class="p">...</span>
<span class="o">--------------------------------------------------------------</span>
<span class="n">Label</span><span class="o">:</span><span class="w"> </span><span class="n">Golden</span><span class="w"> </span><span class="n">Retriever</span><span class="p">,</span><span class="w"> </span><span class="n">Confidence</span><span class="o">:</span><span class="w"> </span><span class="mf">0.2638858</span>
<span class="n">Label</span><span class="o">:</span><span class="w"> </span><span class="n">Kuvasz</span><span class="p">,</span><span class="w"> </span><span class="n">Confidence</span><span class="o">:</span><span class="w"> </span><span class="mf">0.22160825</span>
<span class="n">Label</span><span class="o">:</span><span class="w"> </span><span class="n">Saluki</span><span class="p">,</span><span class="w"> </span><span class="n">Confidence</span><span class="o">:</span><span class="w"> </span><span class="mf">0.1875134</span>
<span class="n">Label</span><span class="o">:</span><span class="w"> </span><span class="n">Clumber</span><span class="w"> </span><span class="n">Spaniel</span><span class="p">,</span><span class="w"> </span><span class="n">Confidence</span><span class="o">:</span><span class="w"> </span><span class="mf">0.07285915</span>
<span class="n">Label</span><span class="o">:</span><span class="w"> </span><span class="n">Otterhound</span><span class="p">,</span><span class="w"> </span><span class="n">Confidence</span><span class="o">:</span><span class="w"> </span><span class="mf">0.031498097</span>
<span class="n">Label</span><span class="o">:</span><span class="w"> </span><span class="n">borzoi</span><span class="p">,</span><span class="w"> </span><span class="n">Confidence</span><span class="o">:</span><span class="w"> </span><span class="mf">0.027598232</span>
<span class="n">Label</span><span class="o">:</span><span class="w"> </span><span class="n">English</span><span class="w"> </span><span class="k">Set</span><span class="n">ter</span><span class="p">,</span><span class="w"> </span><span class="n">Confidence</span><span class="o">:</span><span class="w"> </span><span class="mf">0.02686022</span>
<span class="n">Label</span><span class="o">:</span><span class="w"> </span><span class="n">Sussex</span><span class="w"> </span><span class="n">Spaniel</span><span class="p">,</span><span class="w"> </span><span class="n">Confidence</span><span class="o">:</span><span class="w"> </span><span class="mf">0.019354017</span>
<span class="n">Label</span><span class="o">:</span><span class="w"> </span><span class="n">Afghan</span><span class="w"> </span><span class="n">Hound</span><span class="p">,</span><span class="w"> </span><span class="n">Confidence</span><span class="o">:</span><span class="w"> </span><span class="mf">0.017119078</span>
<span class="n">Label</span><span class="o">:</span><span class="w"> </span><span class="n">Pyrenean</span><span class="w"> </span><span class="n">Mountain</span><span class="w"> </span><span class="n">Dog</span><span class="p">,</span><span class="w"> </span><span class="n">Confidence</span><span class="o">:</span><span class="w"> </span><span class="mf">0.010476385</span>
</code></pre></div>

<p>出現了額外的警告訊息，提示某些運算不支援。雖然還是有成功跑出結果，但是計算出來的數值跟用 CPU 與 QNN 版的 ONNX 自己量化模型的結果不同，明顯有誤。</p>
<h2 id="_7">心得</h2>
<p>經過測試，ONNX Runtime 與 QNN EP 的組合，要使用 NPU 需要做不少額外的前置處理，且不只支援部分運算或是存在 bug。
此外，量化模型需要使用 QNN 版的 ONNX，否則執行可能會有問題，相容性還有待提升，希望微軟與高通可以讓 QNN EP 在 ONNX 的開發體驗更友好。</p>
  </div>
  <div class="tag-cloud">
    <p>
      <a href="https://yaticl.github.io/tag/machine-learning.html">Machine Learning</a>
      <a href="https://yaticl.github.io/tag/ai.html">AI</a>
      <a href="https://yaticl.github.io/tag/onnx.html">ONNX</a>
      <a href="https://yaticl.github.io/tag/directml.html">DirectML</a>
      <a href="https://yaticl.github.io/tag/arm64.html">ARM64</a>
    </p>
  </div>


  <div class="neighbors">
    <a class="btn float-left" href="https://yaticl.github.io/stable-diffusion-accelerated-by-ONNX-Runtime-and-directML.html" title="使用 ONNX Runtime 與 DirectML 加速 Stable Diffusing 模型推理">
      <i class="fa fa-angle-left"></i> 上一篇文章
    </a>
    <a class="btn float-right" href="https://yaticl.github.io/build-opencv-on-windows-arm64.html" title="建置支援 Windows ARM64 的 OpenCV">
      下一篇文章 <i class="fa fa-angle-right"></i>
    </a>
  </div>

  <div class="related-posts">
    <h4>你可能也感興趣</h4>
    <ul class="related-posts">
      <li><a href="https://yaticl.github.io/stable-diffusion-accelerated-by-ONNX-Runtime-and-directML.html">使用 ONNX Runtime 與 DirectML 加速 Stable Diffusing 模型推理</a></li>
      <li><a href="https://yaticl.github.io/image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-directML.html">使用 ONNX Runtime 與 DirectML 加速 ResNet50 影像分類推理</a></li>
      <li><a href="https://yaticl.github.io/build-opencv-on-windows-arm64.html">建置支援 Windows ARM64 的 OpenCV</a></li>
    </ul>
  </div>



  <section>
    <p id="post-share-links">
      分享到:
      <a href="https://sharetodiaspora.github.io/?title=%E4%BD%BF%E7%94%A8%20ONNX%20Runtime%20%E8%88%87%20Qualcomm%20QNN%20%E5%8A%A0%E9%80%9F%E5%BD%B1%E5%83%8F%E5%88%86%E9%A1%9E%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86&url=https%3A//yaticl.github.io/image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-QNN.html" target="_blank" title="分享到 Diaspora">Diaspora</a>
      ❄
      <a href="https://twitter.com/intent/tweet?text=%E4%BD%BF%E7%94%A8%20ONNX%20Runtime%20%E8%88%87%20Qualcomm%20QNN%20%E5%8A%A0%E9%80%9F%E5%BD%B1%E5%83%8F%E5%88%86%E9%A1%9E%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86&url=https%3A//yaticl.github.io/image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-QNN.html&hashtags=machine-learning,ai,onnx,directml,arm64" target="_blank" title="分享到 Twitter">Twitter</a>
      ❄
      <a href="https://www.facebook.com/sharer/sharer.php?u=https%3A//yaticl.github.io/image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-QNN.html" target="_blank" title="分享到 Facebook">Facebook</a>
      ❄
      <a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3A//yaticl.github.io/image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-QNN.html&title=%E4%BD%BF%E7%94%A8%20ONNX%20Runtime%20%E8%88%87%20Qualcomm%20QNN%20%E5%8A%A0%E9%80%9F%E5%BD%B1%E5%83%8F%E5%88%86%E9%A1%9E%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86&summary=2024-05-24%20%E6%9B%B4%E6%96%B0%EF%BC%9A%E7%94%B1%E6%96%BC%20ONNX%20QNN%20EP%20%E6%96%87%E4%BB%B6%E6%9B%B4%E6%96%B0%E5%BE%88%E5%A4%9A%EF%BC%8C%E5%9B%A0%E6%AD%A4%E6%96%87%E7%AB%A0%E5%9B%A0%E6%87%89%E8%80%8C%E5%A4%A7%E5%B9%85%E6%9B%B4%E6%96%B0%E3%80%82%0A%E8%83%8C%E6%99%AF%0A%E7%94%B1%E6%96%BC%E6%9C%80%E8%BF%91%E7%94%9F%E6%88%90%E5%BC%8F%20AI%20%E7%9A%84%E8%88%88%E8%B5%B7%EF%BC%8C%E5%A6%82%20ChatGPT%20%E8%88%87%20DALL%C2%B7E%EF%BC%8C%E5%BE%AE%E8%BB%9F%E6%94%9C%E6%89%8B%E5%BB%A0%E5%95%86%E5%80%91%20%E2%80%A6&source=https%3A//yaticl.github.io/image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-QNN.html" target="_blank" title="分享到 LinkedIn">LinkedIn</a>
      ❄
      <a href="https://news.ycombinator.com/submitlink?t=%E4%BD%BF%E7%94%A8%20ONNX%20Runtime%20%E8%88%87%20Qualcomm%20QNN%20%E5%8A%A0%E9%80%9F%E5%BD%B1%E5%83%8F%E5%88%86%E9%A1%9E%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86&u=https%3A//yaticl.github.io/image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-QNN.html" target="_blank" title="分享到 HackerNews">HackerNews</a>
      ❄
      <a href="mailto:?subject=%E4%BD%BF%E7%94%A8%20ONNX%20Runtime%20%E8%88%87%20Qualcomm%20QNN%20%E5%8A%A0%E9%80%9F%E5%BD%B1%E5%83%8F%E5%88%86%E9%A1%9E%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86&amp;body=https%3A//yaticl.github.io/image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-QNN.html" target="_blank" title="從 Email 分享">Email</a>
      ❄
      <a href="https://www.reddit.com/submit?url=https%3A//yaticl.github.io/image-classification-with-ResNet50-accelerated-by-ONNX-Runtime-and-QNN.html&title=%E4%BD%BF%E7%94%A8%20ONNX%20Runtime%20%E8%88%87%20Qualcomm%20QNN%20%E5%8A%A0%E9%80%9F%E5%BD%B1%E5%83%8F%E5%88%86%E9%A1%9E%E6%A8%A1%E5%9E%8B%E6%8E%A8%E7%90%86" target="_blank" title="從 Reddit 分享">Reddit</a>
    </p>
  </section>
</article>

    <footer>
<p>&copy;  </p>
<p>
Built with <a href="http://getpelican.com" target="_blank">Pelican</a> using <a href="http://bit.ly/flex-pelican" target="_blank">Flex</a> theme
</p>    </footer>
  </main>




<script type="application/ld+json">
{
  "@context" : "http://schema.org",
  "@type" : "Blog",
  "name": " Ya-Ti's Blog ",
  "url" : "https://yaticl.github.io",
  "image": "https://yaticl.github.io/images/profile.jpg",
  "description": ""
}
</script>

    <script>
      $(document).ready(function() {
        $('#tipue_search_input').tipuesearch();
      });
    </script>

</body>
</html>